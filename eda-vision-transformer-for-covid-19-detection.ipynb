{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# **About this Notebook**\nIn this kernel, we will learn how to\n* Analyze a dataset of chest X-rays (images). They are of people with Covid-19, other pneumonias, and healthy people.\n* Convert data into tensors\n* Create **ViT(Vision Transformer) from scratch**\n\n![ViT](https://upload.wikimedia.org/wikipedia/commons/thumb/3/3e/Vision_Transformer.gif/675px-Vision_Transformer.gif)\n\n* Train the model\n* Measure time & memory **complexity**\n* Create a classification report with **confusion matrix, accuracy, F1-Score**\n* Implement **stratified k-folding** to practice working with small datasets\n* Try to implement **GRAD-CAM** to understand where our model is paying attention to in the training process.\n\n\nIf you find this kernel useful, Please **Upvote** it!","metadata":{}},{"cell_type":"markdown","source":"# Importing Necessary Libraries & Packages","metadata":{}},{"cell_type":"code","source":"import tensorflow as tf\nimport numpy as np\nimport pandas as pd\nimport tensorflow_addons as tfa\n\nimport glob, random, os, warnings\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport cv2\nfrom tqdm import tqdm\nimport albumentations as A\nimport shutil\nfrom datetime import datetime\nfrom time import time\n\n\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import confusion_matrix, classification_report\n\n\nimport tensorflow.keras.layers as L\n#from tensorflow.keras import layers\nfrom tensorflow.keras.layers import (\n    Dense,\n    Dropout,\n    LayerNormalization,\n)\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\n\ndef seed_everything(seed = 0):\n    random.seed(seed)\n    np.random.seed(seed)\n    tf.random.set_seed(seed)\n    os.environ['PYTHONHASHSEED'] = str(seed)\n    os.environ['TF_DETERMINISTIC_OPS'] = \"True\"\n    os.environ[\"TF_DISABLE_SEGMENT_REDUCTION_OP_DETERMINISM_EXCEPTIONS\"] = \"True\"\n\nseed_everything()\nwarnings.filterwarnings('ignore')\n\n\nprint('TensorFlow Version ' + tf.__version__)","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2022-12-21T14:26:51.845411Z","iopub.execute_input":"2022-12-21T14:26:51.845775Z","iopub.status.idle":"2022-12-21T14:26:51.855932Z","shell.execute_reply.started":"2022-12-21T14:26:51.845744Z","shell.execute_reply":"2022-12-21T14:26:51.854974Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**We have 3 classes as our output.**\n* pneumonia\n* covid\n* normal","metadata":{}},{"cell_type":"code","source":"class_to_label_map = {2 : 'pneumonia', 1 : 'covid', 0 : 'normal'} \n","metadata":{"execution":{"iopub.status.busy":"2022-12-21T14:26:54.563374Z","iopub.execute_input":"2022-12-21T14:26:54.563732Z","iopub.status.idle":"2022-12-21T14:26:54.568398Z","shell.execute_reply.started":"2022-12-21T14:26:54.563701Z","shell.execute_reply":"2022-12-21T14:26:54.567200Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Let's create a DataFrame with the data!","metadata":{}},{"cell_type":"code","source":"df = pd.DataFrame(columns =['class', 'directory'])  \nfor path, names, filenames in os.walk('/kaggle/input/covid19-chest-xray-dataset/covid19-pneumonia-normal-chest-xraypa-dataset/COVID19_Pneumonia_Normal_Chest_Xray_PA_Dataset/normal'):\n    for filename in filenames:\n        df.loc[-1] = [\"normal\", ('normal/' + filename)] \n        df.index = df.index + 1 \n        df = df.sort_index() \nfor path, names, filenames in os.walk('/kaggle/input/covid19-chest-xray-dataset/covid19-pneumonia-normal-chest-xraypa-dataset/COVID19_Pneumonia_Normal_Chest_Xray_PA_Dataset/covid'):\n    for filename in filenames:\n        df.loc[-1] = [\"covid\", ('covid/' + filename)] \n        df.index = df.index + 1 \n        df = df.sort_index() \nfor path, names, filenames in os.walk('/kaggle/input/covid19-chest-xray-dataset/covid19-pneumonia-normal-chest-xraypa-dataset/COVID19_Pneumonia_Normal_Chest_Xray_PA_Dataset/pneumonia'):\n    for filename in filenames:\n        df.loc[-1] = [\"pneumonia\", ('pneumonia/' + filename)] \n        df.index = df.index + 1 \n        df = df.sort_index()","metadata":{"execution":{"iopub.status.busy":"2022-12-21T14:26:56.319174Z","iopub.execute_input":"2022-12-21T14:26:56.319812Z","iopub.status.idle":"2022-12-21T14:27:07.853577Z","shell.execute_reply.started":"2022-12-21T14:26:56.319777Z","shell.execute_reply":"2022-12-21T14:27:07.852638Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"We have it, we can start working with it now!","metadata":{}},{"cell_type":"code","source":"df","metadata":{"execution":{"iopub.status.busy":"2022-12-21T14:27:19.375817Z","iopub.execute_input":"2022-12-21T14:27:19.376536Z","iopub.status.idle":"2022-12-21T14:27:19.394381Z","shell.execute_reply.started":"2022-12-21T14:27:19.376500Z","shell.execute_reply":"2022-12-21T14:27:19.393429Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Let's check if there's any imbalance in the data!\n\nThe number of cases are equal so we're good!","metadata":{}},{"cell_type":"code","source":"plt.figure(figsize=(12,3))\nsplot = sns.countplot(data = df.sort_values(by='class'), y ='class', palette='cool', saturation=0.9)\nplt.bar_label(container=splot.containers[0], \n              labels=['covid', 'normal', 'pneumonia'], \n              label_type='center', size=15, color='w')\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2022-12-21T14:27:21.066019Z","iopub.execute_input":"2022-12-21T14:27:21.066365Z","iopub.status.idle":"2022-12-21T14:27:21.285746Z","shell.execute_reply.started":"2022-12-21T14:27:21.066336Z","shell.execute_reply":"2022-12-21T14:27:21.284867Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Let's see one of the pictures and its attributes!","metadata":{}},{"cell_type":"code","source":"plt.figure()\nimage = cv2.imread(\"/kaggle/input/covid19-chest-xray-dataset/covid19-pneumonia-normal-chest-xraypa-dataset/COVID19_Pneumonia_Normal_Chest_Xray_PA_Dataset/covid/03BF7561-A9BA-4C3C-B8A0-D3E585F73F3C-1068x1083.jpeg\")\nplt.imshow(image)\nplt.axis('off')\nplt.show() \n\nprint('Image Shape: {}'.format(image.shape))\nprint('Image Height: {}'.format(image.shape[0]))\nprint('Image Width: {}'.format(image.shape[1]))\nprint('Image Dimension: {}'.format(image.ndim))\nprint('Image Size: {}kb'.format(image.size//1024))\nprint('Image Data Type: {}'.format(image.dtype))\nprint('Maximum RGB value of the image: {}'.format(image.max()))\nprint('Minimum RGB value of the image: {}'.format(image.min()))","metadata":{"execution":{"iopub.status.busy":"2022-12-21T14:27:23.019837Z","iopub.execute_input":"2022-12-21T14:27:23.020200Z","iopub.status.idle":"2022-12-21T14:27:23.311654Z","shell.execute_reply.started":"2022-12-21T14:27:23.020170Z","shell.execute_reply":"2022-12-21T14:27:23.310596Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Let's create Train & Test sets. \n\n* **Train set --> 80%**\n* **Test set --> 20%**","metadata":{}},{"cell_type":"code","source":"X_train, X_test, Y_train, Y_test = train_test_split(df['directory'], df['class'], stratify= df['class'], test_size=0.20, random_state=1)","metadata":{"execution":{"iopub.status.busy":"2022-12-21T14:27:26.258998Z","iopub.execute_input":"2022-12-21T14:27:26.259378Z","iopub.status.idle":"2022-12-21T14:27:26.270535Z","shell.execute_reply.started":"2022-12-21T14:27:26.259346Z","shell.execute_reply":"2022-12-21T14:27:26.269599Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(f\"\"\"\n{'-'*40}\n# Train samples: {Y_train.shape}\n# Test samples: {Y_test.shape}\n{'-'*40}\n\"\"\")","metadata":{"execution":{"iopub.status.busy":"2022-12-21T14:27:28.517838Z","iopub.execute_input":"2022-12-21T14:27:28.518206Z","iopub.status.idle":"2022-12-21T14:27:28.524321Z","shell.execute_reply.started":"2022-12-21T14:27:28.518177Z","shell.execute_reply":"2022-12-21T14:27:28.523127Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**We need to copy the images from input to output directory to work with them later on! Below is a custom method to copy images according to the dataframes we created as train & test sets!**","metadata":{}},{"cell_type":"code","source":"def copy_images(df, directory):\n    input_path = \"/kaggle/input/covid19-chest-xray-dataset/covid19-pneumonia-normal-chest-xraypa-dataset/COVID19_Pneumonia_Normal_Chest_Xray_PA_Dataset\"\n    output_path = \"out/\" + directory \n    \n    #if any old file exists in ouput path, it is removed\n    if os.path.exists(output_path):\n        shutil.rmtree(output_path)\n        \n    #creating folder inside output path\n    if not os.path.exists(output_path):\n        os.makedirs(output_path)\n    \n    #these three subfolders\n    classes = ['normal', 'covid', 'pneumonia']\n    for c in classes:\n        if not os.path.exists(output_path + '/' + c):\n            os.makedirs(output_path + '/' + c)\n    \n    #the original dataframe containing directory for each row, those directory are shifted from path_from to path_to\n    #(that is from input directory to ouput directory)\n    for i, row in df.iterrows():\n        path_from = \"{}/{}\".format(input_path, row['directory'])\n        path_to = \"{}/{}\".format(output_path, row['directory'])\n        shutil.copy(path_from, path_to)","metadata":{"execution":{"iopub.status.busy":"2022-12-21T14:27:30.533816Z","iopub.execute_input":"2022-12-21T14:27:30.534517Z","iopub.status.idle":"2022-12-21T14:27:30.542159Z","shell.execute_reply.started":"2022-12-21T14:27:30.534482Z","shell.execute_reply":"2022-12-21T14:27:30.541100Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_test = pd.concat([X_test, Y_test], axis = 1)\ndf_train = pd.concat([X_train, Y_train], axis = 1)\n\ncopy_images(df_test, 'test')\ncopy_images(df_train, 'train')","metadata":{"execution":{"iopub.status.busy":"2022-12-21T14:27:32.121535Z","iopub.execute_input":"2022-12-21T14:27:32.122252Z","iopub.status.idle":"2022-12-21T14:27:55.805441Z","shell.execute_reply.started":"2022-12-21T14:27:32.122209Z","shell.execute_reply":"2022-12-21T14:27:55.804437Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**PARAMETERS** for the Model","metadata":{}},{"cell_type":"code","source":"train_path = '/kaggle/working/out/train'\ntest_path = '/kaggle/working/out/test'\n\nimage_size = 224\nbatch_size = 16\nn_classes = 3\nlearning_rate = 0.001\nweight_decay = 0.0001\nnum_epochs = 3\n\npatch_size = 6  # Size of the patches to be extract from the input images\nnum_patches = (image_size // patch_size) ** 2\nprojection_dim = 64\nnum_heads = 4\ntransformer_units = [\n    projection_dim * 2,\n    projection_dim,\n]  # Size of the transformer layers\ntransformer_layers = 8","metadata":{"execution":{"iopub.status.busy":"2022-12-21T14:28:00.513188Z","iopub.execute_input":"2022-12-21T14:28:00.513538Z","iopub.status.idle":"2022-12-21T14:28:00.519424Z","shell.execute_reply.started":"2022-12-21T14:28:00.513509Z","shell.execute_reply":"2022-12-21T14:28:00.518206Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"ImageDataGenerator of Keras helps us generate batches of tensor image data with real-time data augmentation. So we're creating \n* Training\n* Validation\n* Test\ndata generators for our model\n\n**!!!!!** We have different ImageDataGenerator for (train&validation) and (test) sets. We don't want to change anything in test set so we're doing it in a seperate line!","metadata":{}},{"cell_type":"code","source":"datagen = tf.keras.preprocessing.image.ImageDataGenerator(rescale=1./255,\n                                                          validation_split = 0.2,\n                                                          featurewise_center = \"True\",\n                                                          featurewise_std_normalization = \"True\")\ntest_datagen = tf.keras.preprocessing.image.ImageDataGenerator(rescale=1./255)\n\ntrain_gen = datagen.flow_from_dataframe(dataframe = df_train,\n                                        directory = train_path,\n                                        x_col = 'directory',\n                                        y_col = 'class',\n                                        subset = 'training',\n                                        batch_size = batch_size,\n                                        seed = 1,\n                                        color_mode = 'rgb',\n                                        shuffle = True,\n                                        class_mode = 'categorical',\n                                        target_size = (image_size, image_size))\n\nvalid_gen = datagen.flow_from_dataframe(dataframe = df_train,\n                                        directory = train_path,\n                                        x_col = 'directory',\n                                        y_col = 'class',\n                                        subset = 'validation',\n                                        batch_size = batch_size,\n                                        seed = 1,\n                                        color_mode = 'rgb',\n                                        shuffle = True,\n                                        class_mode = 'categorical',\n                                        target_size = (image_size, image_size))\n\n\ntest_gen = test_datagen.flow_from_directory(\n    directory=r\"./out/test/\",\n    color_mode=\"rgb\",\n    batch_size=1,\n    class_mode=None,\n    shuffle=False,\n    seed=1,\n    target_size = (image_size, image_size)\n)","metadata":{"execution":{"iopub.status.busy":"2022-12-21T14:28:02.991518Z","iopub.execute_input":"2022-12-21T14:28:02.991900Z","iopub.status.idle":"2022-12-21T14:28:03.174429Z","shell.execute_reply.started":"2022-12-21T14:28:02.991867Z","shell.execute_reply":"2022-12-21T14:28:03.173494Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Vision Transformer from Scratch","metadata":{}},{"cell_type":"markdown","source":"## Patch Embedding","metadata":{}},{"cell_type":"code","source":"class PatchEmbedding(tf.keras.layers.Layer):\n    def __init__(self , size , num_of_patches , projection_dim):\n        super().__init__()\n\n        self.size=size\n        self.num_of_patches= num_of_patches + 1\n        self.projection_dim=projection_dim\n\n        self.projection=tf.keras.layers.Dense(projection_dim)\n\n        self.clsToken= tf.Variable(tf.keras.initializers.GlorotNormal()(shape=(1 , 1 , projection_dim)) , trainable=True)\n        #create vector for each patch \n        self.positionalEmbedding = tf.keras.layers.Embedding(self.num_of_patches , projection_dim)\n\n\n    def call(self, inputs):\n        patches = tf.image.extract_patches(inputs , sizes=[1 , self.size , self.size , 1], strides=[1 , self.size , self.size , 1], rates=[1 ,1 ,1 ,1], padding=\"VALID\",)\n        patches=tf.reshape(patches, (tf.shape(inputs)[0], -1, self.size * self.size *3))\n        patches= self.projection(patches)\n\n        # repeat cls token length of batch size\n        clsToken = tf.repeat(self.clsToken , tf.shape(inputs)[0] , 0)\n        patches = tf.concat((clsToken, patches) , axis=1)\n        # create position number for each patch\n        positions = tf.range(0 , self.num_of_patches , 1)[tf.newaxis , ...]\n        positionalEmbedding = self.positionalEmbedding(positions)\n\n        #print(positionalEmbedding)\n        patches= patches + positionalEmbedding\n        return patches","metadata":{"execution":{"iopub.status.busy":"2022-12-21T14:28:05.431968Z","iopub.execute_input":"2022-12-21T14:28:05.432332Z","iopub.status.idle":"2022-12-21T14:28:05.443415Z","shell.execute_reply.started":"2022-12-21T14:28:05.432302Z","shell.execute_reply":"2022-12-21T14:28:05.442189Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Transformer Encoder","metadata":{}},{"cell_type":"code","source":"class TransformerLayer(tf.keras.layers.Layer):\n    def __init__(self , d_model , heads , mlp_rate , dropout_rate=0.1):\n        super().__init__()\n\n        self.layernorm_1 = LayerNormalization(epsilon=1e-6)\n        self.mha= tf.keras.layers.MultiHeadAttention(heads, d_model//heads , dropout=dropout_rate)\n\n        self.layernorm_2 = LayerNormalization(epsilon=1e-6)\n        self.mlp = tf.keras.Sequential([\n                                        Dense(d_model * mlp_rate , activation=\"gelu\"),\n                                        Dropout(dropout_rate),\n                                        Dense(d_model , activation=\"gelu\"),\n                                        Dropout(dropout_rate)\n        ])\n    def call(self , inputs , training=True):\n        out_1 = self.layernorm_1(inputs)\n        out_1 = self.mha(out_1 , out_1 ,training=training)\n        out_1 = inputs + out_1\n\n        out_2= self.layernorm_2(out_1)\n        out_2=self.mlp(out_2 , training=training)\n        out_2 = out_1 + out_2\n\n        return out_2","metadata":{"execution":{"iopub.status.busy":"2022-12-21T14:28:06.333501Z","iopub.execute_input":"2022-12-21T14:28:06.333872Z","iopub.status.idle":"2022-12-21T14:28:06.343620Z","shell.execute_reply.started":"2022-12-21T14:28:06.333834Z","shell.execute_reply":"2022-12-21T14:28:06.341342Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class TransformerEncoder(tf.keras.layers.Layer):\n    def __init__(self , d_model , heads , mlp_rate , num_layers=1 , dropout_rate=0.1):\n        super().__init__()\n\n        self.encoders = [TransformerLayer(d_model , heads , mlp_rate , dropout_rate) for _ in range(num_layers)]\n\n    def call(self , inputs , training=True):\n        x =inputs\n\n        for layer in self.encoders:\n            x = layer(x , training=training)\n\n        return x","metadata":{"execution":{"iopub.status.busy":"2022-12-21T14:28:07.628760Z","iopub.execute_input":"2022-12-21T14:28:07.629428Z","iopub.status.idle":"2022-12-21T14:28:07.635764Z","shell.execute_reply.started":"2022-12-21T14:28:07.629393Z","shell.execute_reply":"2022-12-21T14:28:07.634569Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Putting it all together","metadata":{}},{"cell_type":"code","source":"class ViT(tf.keras.Model):\n    def __init__(self , num_classes , patch_size , num_of_patches , d_model , heads , num_layers , mlp_rate , dropout_rate=0.1):\n        super().__init__()\n\n        self.patchEmbedding = PatchEmbedding(patch_size , num_of_patches , d_model)\n        self.encoder = TransformerEncoder(d_model , heads , mlp_rate  ,num_layers , dropout_rate)\n\n        self.prediction = tf.keras.Sequential([\n                                               tf.keras.layers.Dropout(0.3),\n                                               tf.keras.layers.Dense(mlp_rate * d_model , activation=\"gelu\"),\n                                               tf.keras.layers.Dropout(0.2),       \n                                               tf.keras.layers.Dense(num_classes, activation=\"softmax\")\n\n\n      ])\n    def call(self , inputs ,  training=True):\n        patches = self.patchEmbedding(inputs)\n        encoderResult = self.encoder(patches, training=training)\n\n        clsResult = encoderResult[: , 0 , :]\n\n        prediction = self.prediction(clsResult,\n                                     training=training)\n        return prediction","metadata":{"execution":{"iopub.status.busy":"2022-12-21T14:28:09.380445Z","iopub.execute_input":"2022-12-21T14:28:09.381498Z","iopub.status.idle":"2022-12-21T14:28:09.401914Z","shell.execute_reply.started":"2022-12-21T14:28:09.381439Z","shell.execute_reply":"2022-12-21T14:28:09.400464Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Let's get the X_train, Y_train, X_val, Y_val values and labels to use later","metadata":{}},{"cell_type":"markdown","source":"### Train set first","metadata":{}},{"cell_type":"code","source":"# Store the data in X_train, y_train variables by iterating over the batches\ntrain_gen.reset()\nx_train, y_train = next(train_gen)\nfor i in tqdm(range(int(len(train_gen)/batch_size)-1)): #1st batch is already fetched before the for loop.\n    img, label = next(train_gen)\n    x_train = np.append(x_train, img, axis=0 )\n    y_train = np.append(y_train, label, axis=0)\nprint(x_train.shape, y_train.shape)","metadata":{"execution":{"iopub.status.busy":"2022-12-21T14:28:11.299655Z","iopub.execute_input":"2022-12-21T14:28:11.300340Z","iopub.status.idle":"2022-12-21T14:28:13.523695Z","shell.execute_reply.started":"2022-12-21T14:28:11.300296Z","shell.execute_reply":"2022-12-21T14:28:13.522736Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Validation set second","metadata":{}},{"cell_type":"code","source":"valid_gen.reset()\nx_val, y_val = next(valid_gen)\nfor i in tqdm(range(int(len(valid_gen)/batch_size)-1)): #1st batch is already fetched before the for loop.\n    img, label = next(valid_gen)\n    x_val = np.append(x_val, img, axis=0 )\n    y_val = np.append(y_val, label, axis=0)\nprint(x_val.shape, y_val.shape)","metadata":{"execution":{"iopub.status.busy":"2022-12-21T14:28:14.755675Z","iopub.execute_input":"2022-12-21T14:28:14.756310Z","iopub.status.idle":"2022-12-21T14:28:15.197704Z","shell.execute_reply.started":"2022-12-21T14:28:14.756275Z","shell.execute_reply":"2022-12-21T14:28:15.196724Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## DATA AUGMENTATION METHOD","metadata":{}},{"cell_type":"code","source":"image_size=224\npreprocessingModel = tf.keras.Sequential(\n    [\n        tf.keras.layers.experimental.preprocessing.Normalization(),\n        tf.keras.layers.experimental.preprocessing.Resizing(image_size, image_size),\n    ]\n)\n# Compute the mean and the variance of the training data for normalization.\npreprocessingModel.layers[0].adapt(x_train)\n\naugmentationModel = tf.keras.Sequential(\n    [\n        tf.keras.layers.experimental.preprocessing.RandomFlip(\"horizontal\"),\n        tf.keras.layers.experimental.preprocessing.RandomRotation(factor=0.02),\n        tf.keras.layers.experimental.preprocessing.RandomZoom(\n            height_factor=0.2, width_factor=0.2\n        ),\n    ]\n)","metadata":{"execution":{"iopub.status.busy":"2022-12-21T14:28:17.486476Z","iopub.execute_input":"2022-12-21T14:28:17.486836Z","iopub.status.idle":"2022-12-21T14:28:20.575392Z","shell.execute_reply.started":"2022-12-21T14:28:17.486793Z","shell.execute_reply":"2022-12-21T14:28:20.574438Z"},"_kg_hide-input":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Convert dataset into tensors","metadata":{}},{"cell_type":"code","source":"def convert_to_dataset(data, batch_size, shuffle=False , augment=False):\n    dataset = tf.data.Dataset.from_tensor_slices(data)\n    dataset = dataset.map(lambda x , y: (preprocessingModel(x) [0] , y) , num_parallel_calls=tf.data.AUTOTUNE)\n\n    if shuffle:\n        dataset= dataset.shuffle(len(dataset))\n\n    dataset = dataset.batch(batch_size , drop_remainder=True)\n\n    if augment:\n        dataset = dataset.map(lambda x , y: (augmentationModel(x , training=True) , y) , num_parallel_calls=tf.data.AUTOTUNE)\n\n    return dataset.prefetch(tf.data.AUTOTUNE)","metadata":{"execution":{"iopub.status.busy":"2022-12-21T14:28:23.911515Z","iopub.execute_input":"2022-12-21T14:28:23.911924Z","iopub.status.idle":"2022-12-21T14:28:23.919383Z","shell.execute_reply.started":"2022-12-21T14:28:23.911890Z","shell.execute_reply":"2022-12-21T14:28:23.918095Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"trainingData = convert_to_dataset((x_train , y_train) , batch_size , shuffle=True , augment=True)\nvalData = convert_to_dataset((x_val , y_val) , batch_size , shuffle=False , augment=False)\n\nprint(trainingData)\nprint(valData)\nprint(len(trainingData))","metadata":{"execution":{"iopub.status.busy":"2022-12-21T14:28:26.146699Z","iopub.execute_input":"2022-12-21T14:28:26.147376Z","iopub.status.idle":"2022-12-21T14:28:26.714026Z","shell.execute_reply.started":"2022-12-21T14:28:26.147339Z","shell.execute_reply":"2022-12-21T14:28:26.712257Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Defining other parameters for our model**","metadata":{}},{"cell_type":"code","source":"decay_steps = train_gen.n // train_gen.batch_size\ninitial_learning_rate = learning_rate\n\nlr_decayed_fn = tf.keras.experimental.CosineDecay(initial_learning_rate, decay_steps)\n\nlr_scheduler = tf.keras.callbacks.LearningRateScheduler(lr_decayed_fn)","metadata":{"execution":{"iopub.status.busy":"2022-12-21T14:28:29.776903Z","iopub.execute_input":"2022-12-21T14:28:29.777283Z","iopub.status.idle":"2022-12-21T14:28:29.784152Z","shell.execute_reply.started":"2022-12-21T14:28:29.777251Z","shell.execute_reply":"2022-12-21T14:28:29.782462Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# **Training the Model**","metadata":{}},{"cell_type":"code","source":"optimizer = tf.keras.optimizers.Adam(learning_rate = learning_rate)\n\nmodel = ViT( 3,6,(224//6)**2,64,4,8,2,0.1)\n    \nmodel.compile(optimizer = optimizer, \n              loss = tf.keras.losses.CategoricalCrossentropy(label_smoothing = 0.1), \n              metrics = [tf.keras.metrics.CategoricalAccuracy(name=\"accuracy\"),\n                         tf.keras.metrics.TopKCategoricalAccuracy(5, name=\"top-5-accuracy\"),\n                        ],\n             )\n\n\nSTEP_SIZE_TRAIN = train_gen.n // train_gen.batch_size\nSTEP_SIZE_VALID = valid_gen.n // valid_gen.batch_size\nSTEP_SIZE_TEST = test_gen.n // test_gen.batch_size\n\nearlystopping = tf.keras.callbacks.EarlyStopping(monitor = 'val_accuracy',\n                                                 min_delta = 1e-4,\n                                                 patience = 5,\n                                                 mode = 'max',\n                                                 restore_best_weights = True,\n                                                 verbose = 1)\n\ncheckpointer = tf.keras.callbacks.ModelCheckpoint(filepath = './model.hdf5',\n                                                  monitor = 'val_accuracy', \n                                                  verbose = 1, \n                                                  save_best_only = True,\n                                                  save_weights_only = True,\n                                                  mode = 'max')\n\ncallbacks = [earlystopping, lr_scheduler, checkpointer]\n\nstartTrain = time()\nhistory = model.fit(x = train_gen,\n          steps_per_epoch = STEP_SIZE_TRAIN,\n          validation_data = valid_gen,\n          validation_steps = STEP_SIZE_VALID,\n          epochs = num_epochs,\n          callbacks = callbacks)\ntime_passed = time()-startTrain","metadata":{"execution":{"iopub.status.busy":"2022-12-21T14:28:42.793553Z","iopub.execute_input":"2022-12-21T14:28:42.793949Z","iopub.status.idle":"2022-12-21T14:34:21.135394Z","shell.execute_reply.started":"2022-12-21T14:28:42.793916Z","shell.execute_reply":"2022-12-21T14:34:21.134167Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model.summary()","metadata":{"execution":{"iopub.status.busy":"2022-12-21T14:34:21.137338Z","iopub.execute_input":"2022-12-21T14:34:21.137692Z","iopub.status.idle":"2022-12-21T14:34:21.162343Z","shell.execute_reply.started":"2022-12-21T14:34:21.137656Z","shell.execute_reply":"2022-12-21T14:34:21.161499Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Running time & memory occupation(complexity) of the model","metadata":{}},{"cell_type":"code","source":"print(\"Trainable parameters: \",model.count_params() )\nprint(\"Running time: \",time_passed)","metadata":{"execution":{"iopub.status.busy":"2022-12-21T14:34:52.010279Z","iopub.execute_input":"2022-12-21T14:34:52.010643Z","iopub.status.idle":"2022-12-21T14:34:52.021677Z","shell.execute_reply.started":"2022-12-21T14:34:52.010613Z","shell.execute_reply":"2022-12-21T14:34:52.020386Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.plot(history.history['accuracy'])\nplt.plot(history.history['val_accuracy'])\nplt.title('model accuracy')\nplt.ylabel('accuracy')\nplt.xlabel('epoch')\nplt.legend(['train', 'validation'], loc='lower right')\nplt.show()\n\nplt.plot(history.history['loss'])\nplt.plot(history.history['val_loss'])\nplt.title('train set loss')\n\nplt.ylabel('loss')\nplt.xlabel('epoch')\nplt.legend(['train', 'validation'], loc='upper right')\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2022-12-21T14:34:53.617851Z","iopub.execute_input":"2022-12-21T14:34:53.618199Z","iopub.status.idle":"2022-12-21T14:34:54.032729Z","shell.execute_reply.started":"2022-12-21T14:34:53.618169Z","shell.execute_reply":"2022-12-21T14:34:54.031765Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Let's PREDICT!!","metadata":{}},{"cell_type":"code","source":"test_gen.reset()\npredY=model.predict_generator(\n        test_gen,\n        steps=STEP_SIZE_TEST,\n        verbose=1)\ntestY = test_gen.classes","metadata":{"execution":{"iopub.status.busy":"2022-12-21T14:34:57.305255Z","iopub.execute_input":"2022-12-21T14:34:57.305599Z","iopub.status.idle":"2022-12-21T14:35:20.757168Z","shell.execute_reply.started":"2022-12-21T14:34:57.305570Z","shell.execute_reply":"2022-12-21T14:35:20.756076Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Confusion Matrix","metadata":{}},{"cell_type":"code","source":"from sklearn.metrics import confusion_matrix\nfrom sklearn.metrics import ConfusionMatrixDisplay\n\ncm = confusion_matrix(testY, np.argmax(predY, axis = -1)) # confusion matrix\ncr=(classification_report(testY, np.argmax(predY, axis = -1), target_names=class_to_label_map, output_dict=True, digits=4)) #other scores\n\nlabels = class_to_label_map.keys()\ndisp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=labels)\nfig, ax = plt.subplots(figsize=(10,10))\ndisp.plot(cmap=plt.cm.Blues,ax=ax)\nfor labels in disp.text_.ravel():\n    labels.set_fontsize(30)\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2022-12-21T14:35:41.033501Z","iopub.execute_input":"2022-12-21T14:35:41.033872Z","iopub.status.idle":"2022-12-21T14:35:41.286620Z","shell.execute_reply.started":"2022-12-21T14:35:41.033835Z","shell.execute_reply":"2022-12-21T14:35:41.285717Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Let's print classification report","metadata":{}},{"cell_type":"code","source":"fig, ax = plt.subplots(figsize=(10,10)) \nsns.heatmap(pd.DataFrame(cr).iloc[:-1, :].T, annot=True, ax=ax)","metadata":{"execution":{"iopub.status.busy":"2022-12-21T14:35:45.067534Z","iopub.execute_input":"2022-12-21T14:35:45.068020Z","iopub.status.idle":"2022-12-21T14:35:45.391638Z","shell.execute_reply.started":"2022-12-21T14:35:45.067976Z","shell.execute_reply":"2022-12-21T14:35:45.390735Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# **Now let's try Stratified K-Fold for training**","metadata":{}},{"cell_type":"markdown","source":"**Defining Parameters**","metadata":{}},{"cell_type":"code","source":"train_path = '/kaggle/working/out/train'\ntest_path = '/kaggle/working/out/test'\n\nimage_size = 224\nbatch_size = 16\nn_classes = 3\nlearning_rate = 0.001\nweight_decay = 0.0001\nnum_epochs = 2\n\npatch_size = 6  # Size of the patches to be extract from the input images\nnum_patches = (image_size // patch_size) ** 2\nprojection_dim = 64\nnum_heads = 4\ntransformer_units = [\n    projection_dim * 2,\n    projection_dim,\n]  # Size of the transformer layers\ntransformer_layers = 8","metadata":{"execution":{"iopub.status.busy":"2022-12-15T11:41:59.974781Z","iopub.execute_input":"2022-12-15T11:41:59.975541Z","iopub.status.idle":"2022-12-15T11:41:59.981763Z","shell.execute_reply.started":"2022-12-15T11:41:59.975505Z","shell.execute_reply":"2022-12-15T11:41:59.980615Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"optimizer = tf.keras.optimizers.Adam(learning_rate = learning_rate)\n\nmodel = ViT( 3,6,(224//6)**2,64,4,8,2,0.1)\n    \nmodel.compile(optimizer = optimizer, \n                loss = tf.keras.losses.CategoricalCrossentropy(label_smoothing = 0.1), \n                metrics = [tf.keras.metrics.CategoricalAccuracy(name=\"accuracy\"),\n                tf.keras.metrics.TopKCategoricalAccuracy(5, name=\"top-5-accuracy\"),\n                ],\n                )","metadata":{"execution":{"iopub.status.busy":"2022-12-15T11:42:01.637319Z","iopub.execute_input":"2022-12-15T11:42:01.637702Z","iopub.status.idle":"2022-12-15T11:42:01.712737Z","shell.execute_reply.started":"2022-12-15T11:42:01.637669Z","shell.execute_reply":"2022-12-15T11:42:01.711715Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Let's import the necessary library**","metadata":{}},{"cell_type":"code","source":"from sklearn.model_selection import StratifiedKFold","metadata":{"execution":{"iopub.status.busy":"2022-12-15T11:42:02.354229Z","iopub.execute_input":"2022-12-15T11:42:02.354576Z","iopub.status.idle":"2022-12-15T11:42:02.359929Z","shell.execute_reply.started":"2022-12-15T11:42:02.354548Z","shell.execute_reply":"2022-12-15T11:42:02.358746Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Function to save the model at each 'k'th iteration","metadata":{}},{"cell_type":"markdown","source":"**5 splits with shuffling**","metadata":{}},{"cell_type":"code","source":"Y = df_train[['class']]\n\nskf = StratifiedKFold(n_splits = 5, random_state = 7, shuffle = True) ","metadata":{"execution":{"iopub.status.busy":"2022-12-15T11:42:15.033192Z","iopub.execute_input":"2022-12-15T11:42:15.033710Z","iopub.status.idle":"2022-12-15T11:42:15.044916Z","shell.execute_reply.started":"2022-12-15T11:42:15.033658Z","shell.execute_reply":"2022-12-15T11:42:15.043101Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"histories = []\ntime_list = []\n\ndef New_Model(fold_var):\n    \n    STEP_SIZE_TRAIN = train_gen.n // train_gen.batch_size\n    STEP_SIZE_VALID = valid_gen.n // valid_gen.batch_size\n    STEP_SIZE_TEST = test_gen.n // test_gen.batch_size\n\n    earlystopping = tf.keras.callbacks.EarlyStopping(monitor = 'val_accuracy',\n                                                     min_delta = 1e-4,\n                                                     patience = 5,\n                                                     mode = 'max',\n                                                     restore_best_weights = True,\n                                                     verbose = 1)\n\n    checkpointer = tf.keras.callbacks.ModelCheckpoint(filepath = './model_' + str(fold_var) + '.hdf5',\n                                                      monitor = 'val_accuracy', \n                                                      verbose = 1,\n                                                      save_best_only=True,\n                                                      mode = 'max')\n    \n    callbacks = [earlystopping, lr_scheduler, checkpointer]\n    \n    startTrain = time()\n    history = model.fit(x = train_gen,\n              steps_per_epoch = STEP_SIZE_TRAIN,\n              validation_data = valid_gen,\n              validation_steps = STEP_SIZE_VALID,\n              epochs = num_epochs,\n              callbacks = callbacks)\n    time_list.append(time()-startTrain)\n    \n\n    # store history for each folds\n    histories.append(history)\n    \n    tf.keras.backend.clear_session()","metadata":{"execution":{"iopub.status.busy":"2022-12-15T11:42:17.219807Z","iopub.execute_input":"2022-12-15T11:42:17.220171Z","iopub.status.idle":"2022-12-15T11:42:17.228738Z","shell.execute_reply.started":"2022-12-15T11:42:17.220140Z","shell.execute_reply":"2022-12-15T11:42:17.227622Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"fold_var = 1\n\ndatagen = tf.keras.preprocessing.image.ImageDataGenerator(rescale=1./255,\n                                                        featurewise_center=False,  # set input mean to 0 over the dataset\n                                                        samplewise_center=False,  # set each sample mean to 0\n                                                        featurewise_std_normalization=False,  # divide inputs by std of the dataset\n                                                        samplewise_std_normalization=False,  # divide each input by its std\n                                                        zca_whitening=False,  # apply ZCA whitening\n                                                        rotation_range=5,  # randomly rotate images in the range (degrees, 0 to 180)\n                                                        zoom_range = 0.1, # Randomly zoom image \n                                                        width_shift_range=0.1,  # randomly shift images horizontally (fraction of total width)\n                                                        height_shift_range=0.1,  # randomly shift images vertically (fraction of total height)\n                                                        horizontal_flip=True)  # randomly flip images)  \n\n\n\nfor train_index, val_index in skf.split(np.zeros(len(Y)),Y):\n    training_data = df_train.iloc[train_index]\n    validation_data = df_train.iloc[val_index]\n\n    train_gen = datagen.flow_from_dataframe(dataframe = df_train,\n                                            directory = train_path,\n                                            x_col = 'directory',\n                                            y_col = 'class',\n                                            subset = 'training',\n                                            batch_size = batch_size,\n                                            seed = 1,\n                                            color_mode = 'rgb',\n                                            shuffle = True,\n                                            class_mode = 'categorical',\n                                            target_size = (image_size, image_size))\n\n    valid_gen = datagen.flow_from_dataframe(dataframe = df_train,\n                                            directory = train_path,\n                                            x_col = 'directory',\n                                            y_col = 'class',\n                                            subset = 'validation',\n                                            batch_size = batch_size,\n                                            seed = 1,\n                                            color_mode = 'rgb',\n                                            shuffle = True,\n                                            class_mode = 'categorical',\n                                            target_size = (image_size, image_size))\n    print(); print(\"#\"*50)\n    print(\"Fold: \",fold_var+1)\n    print(\"#\"*50)\n\n    New_Model(fold_var)\n    fold_var += 1\n","metadata":{"execution":{"iopub.status.busy":"2022-12-15T11:42:48.932458Z","iopub.execute_input":"2022-12-15T11:42:48.932902Z","iopub.status.idle":"2022-12-15T12:04:22.117736Z","shell.execute_reply.started":"2022-12-15T11:42:48.932859Z","shell.execute_reply":"2022-12-15T12:04:22.116733Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Running time & memory occupation(complexity) of the model","metadata":{}},{"cell_type":"code","source":"print(\"Trainable parameters: \",model.count_params() )\nprint(\"Running time: \",sum(time_list))","metadata":{"execution":{"iopub.status.busy":"2022-12-15T12:07:32.443301Z","iopub.execute_input":"2022-12-15T12:07:32.443668Z","iopub.status.idle":"2022-12-15T12:07:32.454995Z","shell.execute_reply.started":"2022-12-15T12:07:32.443638Z","shell.execute_reply":"2022-12-15T12:07:32.453745Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_gen = ImageDataGenerator(rescale=1/255.0) # just rescaling for test data\n\n\ntest_gen = datagen.flow_from_directory(\n    directory=r\"./out/test/\",\n    color_mode=\"rgb\",\n    batch_size=1,\n    class_mode=None,\n    shuffle=False,\n    seed=1,\n    target_size = (image_size, image_size)\n)","metadata":{"execution":{"iopub.status.busy":"2022-12-15T12:07:51.622282Z","iopub.execute_input":"2022-12-15T12:07:51.622643Z","iopub.status.idle":"2022-12-15T12:07:51.732276Z","shell.execute_reply.started":"2022-12-15T12:07:51.622613Z","shell.execute_reply":"2022-12-15T12:07:51.731274Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model.metrics_names","metadata":{"execution":{"iopub.status.busy":"2022-12-15T12:07:54.003303Z","iopub.execute_input":"2022-12-15T12:07:54.004253Z","iopub.status.idle":"2022-12-15T12:07:54.012074Z","shell.execute_reply.started":"2022-12-15T12:07:54.004207Z","shell.execute_reply":"2022-12-15T12:07:54.011024Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class_to_label_map = {'pneumonia' : 2, 'covid' : 1, 'normal' : 0}\ntest_gen.reset()\npredY=model.predict_generator(\n        test_gen,\n        steps=STEP_SIZE_TEST,\n        verbose=1)\nprint(predY)\ntestY = test_gen.classes\nconfusion__matrix=confusion_matrix(testY, np.argmax(predY, axis = -1))\ncr=(classification_report(testY, np.argmax(predY, axis = -1), target_names=class_to_label_map, output_dict=True, digits=4))\nprint (cr)\nprint(confusion__matrix)","metadata":{"execution":{"iopub.status.busy":"2022-12-15T12:07:56.037800Z","iopub.execute_input":"2022-12-15T12:07:56.038252Z","iopub.status.idle":"2022-12-15T12:08:25.293155Z","shell.execute_reply.started":"2022-12-15T12:07:56.038212Z","shell.execute_reply":"2022-12-15T12:08:25.291941Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def plot_confusion_matrix(cm,\n                          target_names,\n                          title='Confusion matrix',\n                          cmap=None,\n                          normalize=True):\n\n    import matplotlib.pyplot as plt\n    import numpy as np\n    import itertools\n\n    accuracy = np.trace(cm) / float(np.sum(cm))\n    misclass = 1 - accuracy\n\n    if cmap is None:\n        cmap = plt.get_cmap('Purples')\n\n    plt.figure(figsize=(8, 6))\n    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n    plt.title(title, fontsize = 'larger')\n\n    if target_names is not None:\n        tick_marks = np.arange(len(target_names))\n        plt.xticks(tick_marks, target_names, rotation=45, fontsize = 'larger')\n        plt.yticks(tick_marks, target_names, fontsize = 'larger')\n\n    if normalize:\n        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n\n\n    thresh = cm.max() / 1.5 if normalize else cm.max() / 2\n    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n        if normalize:\n            plt.text(j, i, \"{:0.4f}\".format(cm[i, j]),\n                     horizontalalignment=\"center\",\n                     color=\"white\" if cm[i, j] > thresh else \"blue\", fontsize = 'larger')\n        else:\n            plt.text(j, i, \"{:,}\".format(cm[i, j]),\n                     horizontalalignment=\"center\",\n                     color=\"white\" if cm[i, j] > thresh else \"blue\", fontsize = 'larger')\n\n\n    plt.tight_layout()\n    plt.ylabel('True label', fontsize = 'larger')\n    plt.xlabel('Predicted label', fontsize = 'larger')\n\n    plt.show()\n","metadata":{"execution":{"iopub.status.busy":"2022-12-15T12:09:36.983382Z","iopub.execute_input":"2022-12-15T12:09:36.983743Z","iopub.status.idle":"2022-12-15T12:09:36.996767Z","shell.execute_reply.started":"2022-12-15T12:09:36.983711Z","shell.execute_reply":"2022-12-15T12:09:36.995792Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plot_confusion_matrix(confusion__matrix, \n                      normalize = False,\n                      target_names = ['Normal', 'COVID-19', 'Pneumonia'],\n                      title        = \"Confusion Matrix\")","metadata":{"execution":{"iopub.status.busy":"2022-12-15T12:09:38.206454Z","iopub.execute_input":"2022-12-15T12:09:38.206809Z","iopub.status.idle":"2022-12-15T12:09:38.400059Z","shell.execute_reply.started":"2022-12-15T12:09:38.206778Z","shell.execute_reply":"2022-12-15T12:09:38.398787Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# [NOT COMPLETE YET!!] **GRAD Cam**","metadata":{}},{"cell_type":"markdown","source":"https://www.kaggle.com/code/quadeer15sh/grad-cam-what-do-cnns-see#kln-48","metadata":{}},{"cell_type":"code","source":"model.summary()","metadata":{"execution":{"iopub.status.busy":"2022-12-15T12:09:47.705302Z","iopub.execute_input":"2022-12-15T12:09:47.705652Z","iopub.status.idle":"2022-12-15T12:09:47.720120Z","shell.execute_reply.started":"2022-12-15T12:09:47.705623Z","shell.execute_reply":"2022-12-15T12:09:47.719065Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model.get_layer('sequential_19').summary()","metadata":{"execution":{"iopub.status.busy":"2022-12-15T12:16:52.097509Z","iopub.execute_input":"2022-12-15T12:16:52.097864Z","iopub.status.idle":"2022-12-15T12:16:52.104630Z","shell.execute_reply.started":"2022-12-15T12:16:52.097834Z","shell.execute_reply":"2022-12-15T12:16:52.103525Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"layer_output = model.get_layer('transformer_encoder_1').output\n ","metadata":{"execution":{"iopub.status.busy":"2022-12-15T12:29:14.094955Z","iopub.execute_input":"2022-12-15T12:29:14.095341Z","iopub.status.idle":"2022-12-15T12:29:14.120577Z","shell.execute_reply.started":"2022-12-15T12:29:14.095313Z","shell.execute_reply":"2022-12-15T12:29:14.119035Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#print([layer.name for layer in model.get_layer('sequential_19').layers])\nlayer_output = model.get_layer('sequential_19').get_layer('dense_36').output\nprint(layer_output)","metadata":{"execution":{"iopub.status.busy":"2022-12-15T12:28:41.396081Z","iopub.execute_input":"2022-12-15T12:28:41.396453Z","iopub.status.idle":"2022-12-15T12:28:41.402514Z","shell.execute_reply.started":"2022-12-15T12:28:41.396423Z","shell.execute_reply":"2022-12-15T12:28:41.401392Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"for idx in range(len(model.layers)):\n    print(model.get_layer(index = idx).name)","metadata":{"execution":{"iopub.status.busy":"2022-12-15T12:15:55.206342Z","iopub.execute_input":"2022-12-15T12:15:55.206734Z","iopub.status.idle":"2022-12-15T12:15:55.213162Z","shell.execute_reply.started":"2022-12-15T12:15:55.206701Z","shell.execute_reply":"2022-12-15T12:15:55.212044Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from tensorflow.keras.models import Sequential, Model\n\ndef make_gradcam_heatmap(img_array, model, pred_index=None):\n    \n    grad_model = Model(inputs=model.inputs, outputs=[model.get_layer('sequential_19').get_layer('dense_36').output, model.output])\n\n    with tf.GradientTape() as tape:\n        last_conv_layer_output, preds = grad_model(img_array)\n        if pred_index is None:\n            pred_index = tf.argmax(preds[0])\n        class_channel = preds[:, pred_index]\n\n    grads = tape.gradient(class_channel, last_conv_layer_output)\n\n    pooled_grads = tf.reduce_mean(grads, axis=(0, 1, 2))\n\n    last_conv_layer_output = last_conv_layer_output[0]\n    heatmap = last_conv_layer_output @ pooled_grads[..., tf.newaxis]\n    heatmap = tf.squeeze(heatmap)\n\n    heatmap = tf.maximum(heatmap, 0) / tf.math.reduce_max(heatmap)\n    return heatmap.numpy(), preds","metadata":{"execution":{"iopub.status.busy":"2022-12-15T12:19:00.930773Z","iopub.execute_input":"2022-12-15T12:19:00.931348Z","iopub.status.idle":"2022-12-15T12:19:00.942139Z","shell.execute_reply.started":"2022-12-15T12:19:00.931305Z","shell.execute_reply":"2022-12-15T12:19:00.941019Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import matplotlib.cm as cm","metadata":{"execution":{"iopub.status.busy":"2022-12-15T12:18:01.975134Z","iopub.execute_input":"2022-12-15T12:18:01.975491Z","iopub.status.idle":"2022-12-15T12:18:01.980052Z","shell.execute_reply.started":"2022-12-15T12:18:01.975462Z","shell.execute_reply":"2022-12-15T12:18:01.978879Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_test","metadata":{"execution":{"iopub.status.busy":"2022-12-15T12:18:02.406739Z","iopub.execute_input":"2022-12-15T12:18:02.407419Z","iopub.status.idle":"2022-12-15T12:18:02.418637Z","shell.execute_reply.started":"2022-12-15T12:18:02.407384Z","shell.execute_reply":"2022-12-15T12:18:02.417642Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from tensorflow.keras.preprocessing.image import ImageDataGenerator, array_to_img, img_to_array, load_img\nimg_size = 224","metadata":{"execution":{"iopub.status.busy":"2022-12-15T12:18:02.959560Z","iopub.execute_input":"2022-12-15T12:18:02.960244Z","iopub.status.idle":"2022-12-15T12:18:02.965929Z","shell.execute_reply.started":"2022-12-15T12:18:02.960191Z","shell.execute_reply":"2022-12-15T12:18:02.964819Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def readImage(path):\n    img = load_img(path,color_mode='rgb',target_size=(img_size,img_size))\n    img = img_to_array(img)\n    img = img/255.\n    \n    return img\n","metadata":{"execution":{"iopub.status.busy":"2022-12-15T12:18:04.627042Z","iopub.execute_input":"2022-12-15T12:18:04.627407Z","iopub.status.idle":"2022-12-15T12:18:04.632499Z","shell.execute_reply.started":"2022-12-15T12:18:04.627376Z","shell.execute_reply":"2022-12-15T12:18:04.631411Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def gradCAMImage(image):\n    path = f\"/kaggle/working/out/test/{image}\"\n    img = readImage(path)\n    img = tf.image.resize(img,[224,224])\n    img = np.expand_dims(img,axis=0)\n    heatmap,preds = make_gradcam_heatmap(img,model)\n\n    img = load_img(path)\n    img = img_to_array(img)\n    heatmap = np.uint8(255 * heatmap)\n\n    # Use jet colormap to colorize heatmap\n    jet = cm.get_cmap(\"jet\")\n\n    # Use RGB values of the colormap\n    jet_colors = jet(np.arange(256))[:, :3]\n    jet_heatmap = jet_colors[heatmap]\n\n    # Create an image with RGB colorized heatmap\n    jet_heatmap = tf.keras.preprocessing.image.array_to_img(jet_heatmap)\n    jet_heatmap = jet_heatmap.resize((img.shape[1], img.shape[0]))\n    jet_heatmap = tf.keras.preprocessing.image.img_to_array(jet_heatmap)\n\n    # Superimpose the heatmap on original image\n    superimposed_img = jet_heatmap * 0.8 + img\n    superimposed_img = tf.keras.preprocessing.image.array_to_img(superimposed_img)\n    \n    return superimposed_img","metadata":{"execution":{"iopub.status.busy":"2022-12-15T12:18:04.980849Z","iopub.execute_input":"2022-12-15T12:18:04.981507Z","iopub.status.idle":"2022-12-15T12:18:04.989867Z","shell.execute_reply.started":"2022-12-15T12:18:04.981472Z","shell.execute_reply":"2022-12-15T12:18:04.988792Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def gradcam_of_images(correct_class):\n    grad_images = []\n    temp_df = df_test\n    temp_df = temp_df.reset_index(drop=True)\n    for i in range(15):\n        image = temp_df.directory[i]\n        grad_image = gradCAMImage(image)\n        grad_images.append(grad_image)\n\n    return grad_images","metadata":{"execution":{"iopub.status.busy":"2022-12-15T12:18:05.838728Z","iopub.execute_input":"2022-12-15T12:18:05.839100Z","iopub.status.idle":"2022-12-15T12:18:05.846202Z","shell.execute_reply.started":"2022-12-15T12:18:05.839069Z","shell.execute_reply":"2022-12-15T12:18:05.845037Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"correctly_classified = gradcam_of_images(correct_class=True)","metadata":{"execution":{"iopub.status.busy":"2022-12-15T12:19:06.568498Z","iopub.execute_input":"2022-12-15T12:19:06.568857Z","iopub.status.idle":"2022-12-15T12:19:06.634733Z","shell.execute_reply.started":"2022-12-15T12:19:06.568825Z","shell.execute_reply":"2022-12-15T12:19:06.633339Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def display_heatmaps(classified_images):\n    plt.figure(figsize = (20 , 20))\n    n = 0\n    for i in range(15):\n        n+=1\n        plt.subplot(5 , 5, n)\n        plt.subplots_adjust(hspace = 0.5 , wspace = 0.3)\n        plt.imshow(classified_images[i])\n    plt.show()","metadata":{"execution":{"iopub.status.busy":"2022-12-06T15:03:04.140137Z","iopub.status.idle":"2022-12-06T15:03:04.140940Z","shell.execute_reply.started":"2022-12-06T15:03:04.140674Z","shell.execute_reply":"2022-12-06T15:03:04.140703Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"display_heatmaps(correctly_classified)","metadata":{"execution":{"iopub.status.busy":"2022-12-06T15:03:04.142351Z","iopub.status.idle":"2022-12-06T15:03:04.143130Z","shell.execute_reply.started":"2022-12-06T15:03:04.142846Z","shell.execute_reply":"2022-12-06T15:03:04.142870Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"","metadata":{}}]}